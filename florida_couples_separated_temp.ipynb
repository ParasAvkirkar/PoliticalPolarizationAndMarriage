{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import sys\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import datatable as dt\n",
    "\n",
    "from xgboost import plot_tree\n",
    "from os import walk\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from scipy.spatial.distance import euclidean, pdist, squareform\n",
    "from scipy.stats import skew\n",
    "from scipy.special import expit as sigmoid\n",
    "from scipy.cluster.hierarchy import fclusterdata\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = ''\n",
    "#HISTORY_PATH = \"Voter_History_{0}\"\n",
    "PREPROCESSED_PATH = \"preprocessed/{0}/florida_processed_{0}.csv\"\n",
    "COUPLES_PATH=\"couples/{0}/couples_{0}.csv\"\n",
    "#COUPLES_PATH=\"couples/{0}/couples_FLA_{0}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--old OLD_DATE] [--new NEW_DATE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/rahullachh/.local/share/jupyter/runtime/kernel-91e01f33-7fe7-4db8-a8fa-3aa59185d390.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--old', dest='old_date', action='store', type=str, help='old date value')\n",
    "parser.add_argument('--new', dest='new_date', action='store', type=str, help='new date value')\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessed_date = args.new_date\n",
    "preprocessed_date = str(20190910)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#couples_date = args.old_date\n",
    "couples_date = str(20180313)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_prefix = couples_date + \"_\" + preprocessed_date\n",
    "stat_file_prefix =  couples_date + \"_\" + preprocessed_date\n",
    "\n",
    "import os\n",
    "if not os.path.exists(\"plots/\" + image_file_prefix):\n",
    "    os.makedirs(\"plots/\" + image_file_prefix)\n",
    "\n",
    "if not os.path.exists(\"stats/\" + stat_file_prefix):\n",
    "    os.makedirs(\"stats/\" + stat_file_prefix)\n",
    "    \n",
    "stat_file_path = \"stats/\" + stat_file_prefix + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df = pd.read_csv(PREPROCESSED_PATH.format(preprocessed_date) , sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_cols = ['last_name', 'race', 'first_name']\n",
    "global_df = global_df.dropna(subset=req_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "couples_df = pd.read_csv(COUPLES_PATH.format(couples_date) , sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "couples_df[[\"uniq_addr\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting Addresses of voters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addr_df=global_df[['uniq_addr','voter_id']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "couples_df_found = pd.merge(couples_df, addr_df, left_on=[\"voter_id_L\"], right_on=[\"voter_id\"], suffixes=[\"\",\"_L\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing extra column generated of voter id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del couples_df_found['voter_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "couples_df_found = pd.merge(couples_df_found, addr_df, left_on=[\"voter_id_R\"], right_on=[\"voter_id\"], suffixes=[\"\",\"_R\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing extra column generated of voter id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del couples_df_found['voter_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "couples_df_found[[\"voter_id_L\",\"voter_id_R\", \"uniq_addr_L\",\"uniq_addr_R\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "couples_df_found['separated'] = couples_df_found.apply(lambda x : x.uniq_addr_L != x.uniq_addr_R, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separation percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "couples_df_found['separated'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "couples_df_found['separated'].value_counts()/couples_df_found['separated'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# couples_df_found.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "couples_df_found.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging total separation percentage in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_separated_couples = couples_df_found[couples_df_found[\"separated\"] == True].shape[0]\n",
    "with open(stat_file_path + \"total_separation_percentage.csv\", \"w\") as f:\n",
    "    f.write(\"\\t\".join([\"separated_count\", \"total_count\", \"percentage\"]) + \"\\n\")\n",
    "    f.write(\"\\t\".join([str(total_separated_couples), str(couples_df_found.shape[0]), str(100.0 * total_separated_couples/couples_df_found.shape[0])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert race categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_codes = {\n",
    "    1: \"American Indian/Alaskan Native\",\n",
    "    2: \"Asian/Pacific Islander\",\n",
    "    3: \"Black/Not Hispanic\",\n",
    "    4: \"Hispanic\",\n",
    "    5: \"White\",\n",
    "    6: \"Other\",\n",
    "    7: \"Mutli-racial\",\n",
    "    9: \"Unknown\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting race codes to corresponding race-descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def race_code_lambda(row, subscript):\n",
    "    if pd.isnull(row[\"race_\" + subscript]):\n",
    "        return None\n",
    "    code = int(row[\"race_\" + subscript])\n",
    "    return race_codes[code]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating descriptive race columns is a time consuming process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "couples_df_found[\"race_desc_L\"] = couples_df_found.apply(lambda x: race_code_lambda(x, \"L\"), axis=1)\n",
    "couples_df_found[\"race_desc_R\"] = couples_df_found.apply(lambda x: race_code_lambda(x, \"R\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df[\"race_desc\"] = global_df[\"race\"].apply(lambda x: race_codes[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature wise separation percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"party_affiliation\", \"gender\", \"race_desc\"]\n",
    "unique_dic = {}\n",
    "for c in cols:\n",
    "    unique_dic[c] = set(global_df[c].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographic Percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_affiliation_counts = {}\n",
    "race_counts = {}\n",
    "\n",
    "party_affiliation_percentages = {}\n",
    "race_percentages = {}\n",
    "\n",
    "total = global_df.shape[0]\n",
    "for cat_value in unique_dic[\"party_affiliation\"]:\n",
    "    party_affiliation_counts[cat_value] = global_df[global_df[\"party_affiliation\"] == cat_value].shape[0]\n",
    "    party_affiliation_percentages[cat_value] = 100.0 * global_df[global_df[\"party_affiliation\"] == cat_value].shape[0]/total\n",
    "\n",
    "for cat_value in unique_dic[\"race_desc\"]:\n",
    "    race_counts[str(cat_value)] = global_df[global_df[\"race_desc\"] == cat_value].shape[0]\n",
    "    race_percentages[str(cat_value)] =  100.0 * global_df[global_df[\"race_desc\"] == cat_value].shape[0]/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding Demographics\n",
    "For Race we stick to 5% </br>\n",
    "For Party affiliation we stick to 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_percent_threshold = 5.0\n",
    "race_other_groups = []\n",
    "for cat_value in race_percentages:\n",
    "    if race_percentages[cat_value] <= race_percent_threshold:\n",
    "        race_other_groups.append(cat_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_percent_threshold = 5.0\n",
    "party_other_groups = []\n",
    "for cat_value in party_affiliation_percentages:\n",
    "    if party_affiliation_percentages[cat_value] <= party_percent_threshold:\n",
    "        party_other_groups.append(cat_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement others mapping into global and couples dataframe\n",
    "# def create_others_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(unique_dic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Pair-wise stats by feature\n",
    "Current focus is only on gender/race/political-affiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from itertools import combinations \n",
    "\n",
    "def generate_category_based_on_pair_values(first_val, second_val):\n",
    "    return \"({0}, {1})\".format(str(first_val), str(second_val))\n",
    "\n",
    "def generate_pair_stats_by_feature(global_df, couples_df_found, feature, stats={}, others=[]):\n",
    "    print(\"Collecting uniques by feature: \" + feature)\n",
    "    unique_vals = list(global_df[feature].unique())\n",
    "    cat_combinations = list(combinations(list(unique_vals), 2))\n",
    "    \n",
    "    stats[feature] = {}\n",
    "    print(\"Processing : \" + feature + \" : Total comb: \" + str(len(cat_combinations)))\n",
    "    i = 0\n",
    "    start_time = time.time()\n",
    "    stats[feature][\"Other Categories\"] = {'count': 0, 'total': 0}\n",
    "    for comb in cat_combinations:\n",
    "        first_val = comb[0]\n",
    "        second_val = comb[1]\n",
    "        \n",
    "        left_right = couples_df_found[(couples_df_found[feature + \"_L\"] == first_val) & (couples_df_found[feature + \"_R\"] == second_val)]\n",
    "        right_left = couples_df_found[(couples_df_found[feature + \"_L\"] == second_val) & (couples_df_found[feature + \"_R\"] == first_val)]\n",
    "        \n",
    "        count = left_right[left_right[\"separated\"] == True].shape[0]\n",
    "        count += right_left[right_left[\"separated\"] == True].shape[0]\n",
    "        \n",
    "        stat = {}\n",
    "        stat[\"count\"] = count\n",
    "        \n",
    "        if count == 0:\n",
    "            continue\n",
    "        \n",
    "        if first_val in others or second_val in others:\n",
    "            stats[feature][\"Other Categories\"][\"count\"] += count\n",
    "            stats[feature][\"Other Categories\"][\"total\"] += left_right.shape[0] + right_left.shape[0]\n",
    "            continue\n",
    "        \n",
    "        stat[\"total\"] = left_right.shape[0] + right_left.shape[0]\n",
    "        stat[\"percent\"] = count * 100.0/(left_right.shape[0] + right_left.shape[0])\n",
    "        \n",
    "        category = generate_category_based_on_pair_values(first_val, second_val)\n",
    "        stats[feature][category] = stat\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    print(\"Total value combinations process: \" + str(i) + \" Total time (secs): \" + str(time.time() - start_time))\n",
    "    \n",
    "    print(\"Processing symmetric combinations: \" + feature + \" : Total comb: \" + str(len(unique_vals)))\n",
    "    for val in unique_vals:\n",
    "        subset = couples_df_found[(couples_df_found[feature + \"_L\"] == val) & (couples_df_found[feature + \"_R\"] == val)]\n",
    "        \n",
    "        count = subset[subset[\"separated\"] == True].shape[0]\n",
    "        \n",
    "        if val in others:\n",
    "            stats[feature][\"Other Categories\"][\"count\"] += count\n",
    "            stats[feature][\"Other Categories\"][\"total\"] += subset.shape[0]\n",
    "            continue\n",
    "        \n",
    "        stat = {}\n",
    "        stat[\"count\"] = count\n",
    "        \n",
    "        if count == 0:\n",
    "            continue\n",
    "        \n",
    "        stat[\"total\"] = subset.shape[0]\n",
    "        stat[\"percent\"] = count * 100.0/(subset.shape[0])\n",
    "        \n",
    "        category = generate_category_based_on_pair_values(val, val)\n",
    "        stats[feature][category] = stat\n",
    "        \n",
    "    if len(others) > 0 and stats[feature][\"Other Categories\"][\"count\"] > 0:\n",
    "        stats[feature][\"Other Categories\"][\"percent\"] = 100.0 * stats[feature][\"Other Categories\"][\"count\"]/stats[feature][\"Other Categories\"][\"total\"]\n",
    "    else:\n",
    "        del stats[feature][\"Other Categories\"]\n",
    "    \n",
    "    print(\"Done with processing feature: \" + feature)\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pairwise_stat_by_feature(feature, stats, total_couples=1):\n",
    "    feature_stats = stats[feature]\n",
    "    \n",
    "    figures, axes = plt.subplots(nrows=1, ncols=2, figsize=(20,10))\n",
    "    \n",
    "    percent_stats = []\n",
    "    pair_combinations = []\n",
    "    totals = []\n",
    "    \n",
    "    for pair_comb in feature_stats:\n",
    "        percent_stats.append(feature_stats[pair_comb][\"percent\"])\n",
    "        totals.append(feature_stats[pair_comb][\"total\"])\n",
    "        pair_combinations.append(pair_comb)\n",
    "\n",
    "    plot_df = pd.DataFrame({\"percent\": percent_stats, \"category_combination\": pair_combinations, \"totals\": totals})\n",
    "    plot_df[\"category_combination_percentage\"] = 100.0*plot_df[\"totals\"]/total_couples\n",
    "    \n",
    "    sns.barplot(x=\"percent\", y=\"category_combination\", data=plot_df, ax=axes[0], palette=sns.color_palette(\"Set2\"))\n",
    "    \n",
    "    axes[0].set(xlabel=\"Separation percentage\")\n",
    "    \n",
    "    #     sns.barplot(x=\"category_combination_percentage\", y=\"category_combination\", palette=sns.color_palette(\"Set2\"), data=plot_df, ax=axes[1])\n",
    "\n",
    "    #   Pie chart\n",
    "    labels = pair_combinations\n",
    "    sizes = plot_df[\"category_combination_percentage\"].tolist()\n",
    "    axes[1].pie(sizes, labels=labels, autopct='%1.1f%%', colors=['teal', 'salmon', 'silver', 'lightblue', 'orchid', 'pink', 'lightgreen', 'wheat'])\n",
    "    axes[1].axis('equal')\n",
    "    axes[1].set(xlabel=\"Category percentage out of total couples\")\n",
    "    \n",
    "    \n",
    "    axes[0].spines['right'].set_visible(False)\n",
    "    axes[0].spines['top'].set_visible(False)\n",
    "    axes[1].spines['right'].set_visible(False)\n",
    "    axes[1].spines['top'].set_visible(False)\n",
    "    \n",
    "    #     axes[0].set_title(feature)\n",
    "    #     axes[1].set_title(feature + \" wise couple proportion\")\n",
    "\n",
    "    #     Writing stats into file\n",
    "    stat_file_name = feature + \"_totalCouples-\" + str(total_couples) + \".csv\"\n",
    "    plot_df.to_csv(stat_file_path + stat_file_name, sep=\"\\t\")\n",
    "        \n",
    "    plt.savefig(\"plots/\" + image_file_prefix + \"/\" + image_file_prefix +  \"_pairwise_stat_\" + feature)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = generate_pair_stats_by_feature(global_df, couples_df_found, \"race_desc\", others=race_other_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pairwise_stat_by_feature(\"race_desc\", stats, total_couples=couples_df_found.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = generate_pair_stats_by_feature(global_df, couples_df_found, \"party_affiliation\", others=party_other_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pairwise_stat_by_feature(\"party_affiliation\", stats, total_couples=couples_df_found.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = generate_pair_stats_by_feature(global_df, couples_df_found, \"gender\", others=party_other_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pairwise_stat_by_feature(\"gender\", stats, total_couples=couples_df_found.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw code of combination stats (Obsolete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import combinations\n",
    "# total_separated = couples_df_found[couples_df_found[\"separated\"] == True].shape[0]\n",
    "# stats = {}\n",
    "# for c in cols:\n",
    "#     cat_combinations = list(combinations(list(unique_dic[c]), 2))\n",
    "#     stats[c] = {}\n",
    "#     print(\"Processing : \" + c + \" : Total comb: \" + str(len(cat_combinations)))\n",
    "#     i = 0\n",
    "#     for comb in cat_combinations:\n",
    "#         first_val = comb[0]\n",
    "#         second_val = comb[1]\n",
    "        \n",
    "#         left_right = couples_df_found[(couples_df_found[c + \"_L\"] == first_val) & (couples_df_found[c + \"_R\"] == second_val)]\n",
    "#         right_left = couples_df_found[(couples_df_found[c + \"_L\"] == second_val) & (couples_df_found[c + \"_R\"] == first_val)]\n",
    "#         count = left_right[left_right[\"separated\"] == True].shape[0]\n",
    "#         count += right_left[right_left[\"separated\"] == True].shape[0]\n",
    "#         stats[c][str(first_val) + \"_\" + str(second_val)] = count\n",
    "#         stats[c][str(first_val) + \"_\" + str(second_val) + \"_\" + \"total\"] = left_right.shape[0] + right_left.shape[0]\n",
    "#         i += 1\n",
    "        \n",
    "#     print(\"Done with comb: \" + str(i))\n",
    "    \n",
    "#     print(\"Processing symmetric combinations: \" + c + \" : Total comb: \" + str(len(unique_dic[c])))\n",
    "#     unique_vals = unique_dic[c]\n",
    "#     for val in unique_vals:\n",
    "#         subset = couples_df_found[(couples_df_found[c + \"_L\"] == val) & (couples_df_found[c + \"_R\"] == val)]\n",
    "#         count = subset[subset[\"separated\"] == True].shape[0]\n",
    "#         stats[c][str(val) + \"_\" + str(val)] = count\n",
    "#         stats[c][str(val) + \"_\" + str(val) + \"_\" + \"total\"] = subset.shape[0]\n",
    "    \n",
    "#     print(\"Done with processing column: \" + c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw code of plot (Obsolete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figures, axes = plt.subplots(nrows=2, ncols=1, figsize=(20,30))\n",
    "# race_df = None\n",
    "# index = 0\n",
    "# for col in stats:\n",
    "#     col_stats = stats[col]\n",
    "#     percent_stats = {}\n",
    "#     for c in col_stats:\n",
    "#         if \"total\" in c:\n",
    "#             continue\n",
    "        \n",
    "#         total = col_stats[c + \"_\" + \"total\"]\n",
    "#         if total == 0:\n",
    "#             continue\n",
    "            \n",
    "#         p = col_stats[c] * 100.0/total\n",
    "#         if p < 5.0:\n",
    "#             continue\n",
    "#         percent_stats[c] = p\n",
    "    \n",
    "#     plot_df = pd.DataFrame({\"percent\": list(percent_stats.values()), \"category\": list(percent_stats.keys()) })\n",
    "\n",
    "#     plot_df[\"percent_str\"] = plot_df[\"percent\"].apply(str)\n",
    "    \n",
    "# #     sns.barplot(x=\"category\", y=\"percent\", data=plot_df, ax=axes[index])\n",
    "    \n",
    "# #     sns.barplot(x=\"percent_str\", y=\"category\", data=plot_df, ax=axes[index])\n",
    "#     if col == \"race\":\n",
    "#         race_df = plot_df\n",
    "# #         sns.barplot(x=\"category\", y=\"percent\", data=plot_df, ax=axes[index])\n",
    "#     else:\n",
    "#         sns.barplot(x=\"percent\", y=\"category\", data=plot_df, ax=axes[index])\n",
    "#         axes[index].set_title(col)\n",
    "        \n",
    "\n",
    "#     index += 1\n",
    "\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.barplot(x=\"percent_round\", y=\"category\", data=race_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "couples_df_found.age_diff.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_diff_total_counts = couples_df_found.groupby([\"age_diff\"])[\"age_diff\"].agg([\"count\"]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_diff_total_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.clear()\n",
    "plt.close()\n",
    "ax = sns.barplot(x=\"age_diff\", y=\"count\", data=age_diff_total_counts)\n",
    "ax.set(xlabel='age difference between couples', ylabel='couples count')\n",
    "plt.savefig(\"plots/\" + image_file_prefix + \"/\" + image_file_prefix + \"_age_diff_aggregation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_diff_separation_stats = couples_df_found[couples_df_found[\"separated\"]==True].groupby([\"age_diff\"])[\"age_diff\"].agg([\"count\"]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_diff_separation_stats = pd.merge(age_diff_total_counts, age_diff_separation_stats, on=[\"age_diff\"], suffixes=(\"_total\", \"_separated\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_diff_separation_stats[\"percent\"] = 100.0 * age_diff_separation_stats[\"count_separated\"]/age_diff_separation_stats[\"count_total\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_diff_separation_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_diff_separation_stats.to_csv(stat_file_path + \"age_diff_separation_stats.csv\", sep='\\t', header=[\"age_diff\", \"counts_of_that_age_diff\", \"separated_count\", \"separated_percentage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=\"age_diff\", y=\"percent\", data=age_diff_separation_stats, )\n",
    "ax.set(xlabel='age difference between couples', ylabel='couples separation percent')\n",
    "plt.savefig(\"plots/\" + image_file_prefix + \"/\" + image_file_prefix + \"_age_diff_separation_percentages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.stats as stats\n",
    "# pearson_corr, corr_pvalue = stats.pearsonr(age_diff_separation_stats['age_diff'], age_diff_separation_stats['percent'])\n",
    "# print('Correlation of Age Diff Vs separation rate: {} \\nP_value: {}'.format(pearson_corr, corr_pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cf_polarized = np.where(((couples_df_found[\"party_affiliation_L\"] == \"DEM\") & (couples_df_found[\"party_affiliation_R\"] == \"REP\")) |\n",
    "#                         ((couples_df_found[\"party_affiliation_L\"] == \"REP\") & (couples_df_found[\"party_affiliation_R\"] == \"DEM\"))\n",
    "#                         , 1, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cf_separated = np.where(couples_df_found[\"separated\"] == True, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pearson_corr, corr_pvalue = stats.pearsonr(couples_df_stat[\"no\"], couples_df_stat[\"separation_percent\"])\n",
    "#print('Correlation of Polarized couples (DEM/REP) Vs their separation rate: {} \\nP_value: {}'.format(pearson_corr, corr_pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cf_polarized_all = np.where(((couples_df_found[\"party_affiliation_L\"] == \"DEM\") & (couples_df_found[\"party_affiliation_R\"] == \"DEM\"))\n",
    "#                             | ((couples_df_found[\"party_affiliation_L\"] == \"REP\") & (couples_df_found[\"party_affiliation_R\"] == \"REP\"))\n",
    "#                             | ((couples_df_found[\"party_affiliation_L\"] == \"NPA\") & (couples_df_found[\"party_affiliation_R\"] == \"NPA\"))\n",
    "#                         , 0, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pearson_corr, corr_pvalue = stats.pearsonr(cf_polarized_all, cf_separated)\n",
    "#print('Correlation of Polarized couples Vs their separation rate: {} \\nP_value: {}'.format(pearson_corr, corr_pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#couples_df_stat = pd.read_csv(\"stats/20160307_20180313/party_affiliation_totalCouples-2709111.csv\" , sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#couples_df_stat.columns = [\"no\", \"separation_percent\",\"cat_comb\",\"total\",\"cat_comb_percent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#couples_df_stat[\"no\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jaccard_score(cf_polarized_all, cf_separated)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.crosstab(cf_polarized_all, cf_separated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import matthews_corrcoef\n",
    "#matthews_corrcoef(cf_separated, cf_polarized_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "#print(chi2_contingency(pd.crosstab(cf_polarized_all, cf_separated)))\n",
    "\n",
    "def cramers_corrected_stat(confusion_matrix):\n",
    "    \"\"\" calculate Cramers V statistic for categorial-categorial association.\n",
    "        uses correction from Bergsma and Wicher, \n",
    "        Journal of the Korean Statistical Society 42 (2013): 323-328\n",
    "    \"\"\"\n",
    "    chi2 = chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum()\n",
    "    phi2 = chi2/n\n",
    "    r,k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    return np.sqrt(phi2corr / min( (kcorr-1), (rcorr-1)))\n",
    "\n",
    "#cramers_corrected_stat(pd.crosstab(cf_polarized_all, cf_separated))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
